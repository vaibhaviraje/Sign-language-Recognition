{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97b2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout,Convolution2D,MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "import cv2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74980be4",
   "metadata": {},
   "source": [
    "# Create Directories of Live Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6706e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\"):\n",
    "    os.mkdir(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Train\"):\n",
    "    os.mkdir(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Train\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Valid\"):\n",
    "    os.mkdir(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Valid\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Test\"):\n",
    "    os.mkdir(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Test\")\n",
    "    \n",
    "path=\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\"\n",
    "# for i in range(10):\n",
    "#     if not os.path.exists(path +\"\\\\Train\\\\\" +str(i)):\n",
    "#         os.makedirs(path +\"\\\\Train\\\\\" +str(i))\n",
    "#     if not os.path.exists(path +\"\\\\Valid\\\\\" +str(i)):\n",
    "#         os.makedirs(path +\"\\\\Valid\\\\\" +str(i))\n",
    "#     if not os.path.exists(path +\"\\\\Test\\\\\" +str(i)):\n",
    "#         os.makedirs(path +\"\\\\Test\\\\\"+ str(i))\n",
    "\n",
    "for i in string.ascii_uppercase:\n",
    "    if not os.path.exists(path +\"\\\\Train\\\\\" + i):\n",
    "        os.makedirs(path +\"\\\\Train\\\\\" +i)\n",
    "    if not os.path.exists(path +\"\\\\Valid\\\\\"  + i):\n",
    "        os.makedirs(path +\"\\\\Valid\\\\\" +i)\n",
    "    if not os.path.exists(path +\"\\\\Test\\\\\"+ i):\n",
    "        os.makedirs(path +\"\\\\Test\\\\\"+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50331cf6",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7dab7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (\u001b[38;5;241m180\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m), (\u001b[38;5;241m520\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m411\u001b[39m), (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m) ,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Extracting the ROI\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m roi \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m410\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m520\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     90\u001b[0m roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(roi, (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m))\n\u001b[0;32m     92\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "directory=\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Train\\\\\"\n",
    "directory1=\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\\\\Valid\\\\\"\n",
    "minValue = 70\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "interrupt = -1  \n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Getting count of existing images\n",
    "    count = {\n",
    "             'zero': len(os.listdir(directory1+\"/0\")),\n",
    "#              'one': len(os.listdir(directory+\"/1\")),\n",
    "#              'two': len(os.listdir(directory+\"/2\")),\n",
    "#              'three': len(os.listdir(directory+\"/3\")),\n",
    "#              'four': len(os.listdir(directory+\"/4\")),\n",
    "#              'five': len(os.listdir(directory+\"/5\")),\n",
    "#              'six': len(os.listdir(directory+\"/6\")),\n",
    "#              'seven': len(os.listdir(directory+\"/7\")),\n",
    "#              'eight': len(os.listdir(directory+\"/8\")),\n",
    "#              'nine': len(os.listdir(directory+\"/9\")),\n",
    "             'a': len(os.listdir(directory1+\"/A\")),\n",
    "             'b': len(os.listdir(directory1+\"/B\")),\n",
    "             'c': len(os.listdir(directory1+\"/C\")),\n",
    "             'd': len(os.listdir(directory1+\"/D\")),\n",
    "             'e': len(os.listdir(directory1+\"/E\")),\n",
    "             'f': len(os.listdir(directory1+\"/F\")),\n",
    "             'g': len(os.listdir(directory1+\"/G\")),\n",
    "             'h': len(os.listdir(directory1+\"/H\")),\n",
    "             'i': len(os.listdir(directory1+\"/I\")),\n",
    "             'j': len(os.listdir(directory1+\"/J\")),\n",
    "             'k': len(os.listdir(directory1+\"/K\")),\n",
    "             'l': len(os.listdir(directory1+\"/L\")),\n",
    "             'm': len(os.listdir(directory1+\"/M\")),\n",
    "             'n': len(os.listdir(directory1+\"/N\")),\n",
    "             'o': len(os.listdir(directory1+\"/O\")),\n",
    "             'p': len(os.listdir(directory1+\"/P\")),\n",
    "             'q': len(os.listdir(directory1+\"/Q\")),\n",
    "             'r': len(os.listdir(directory1+\"/R\")),\n",
    "             's': len(os.listdir(directory1+\"/S\")),\n",
    "             't': len(os.listdir(directory1+\"/T\")),\n",
    "             'u': len(os.listdir(directory1+\"/U\")),\n",
    "             'v': len(os.listdir(directory1+\"/V\")),\n",
    "             'w': len(os.listdir(directory1+\"/W\")),\n",
    "             'x': len(os.listdir(directory1+\"/X\")),\n",
    "             'y': len(os.listdir(directory1+\"/Y\")),\n",
    "             'z': len(os.listdir(directory1+\"/Z\"))\n",
    "             }\n",
    "    \n",
    "    # Printing the count in each set to the screen\n",
    "    # cv2.putText(frame, \"MODE : \"+mode, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    # cv2.putText(frame, \"IMAGE COUNT\", (10, ), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"0 : \"+str(count['zero']), (10, 40), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"1 : \"+str(count['one']), (10, 55), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"2 : \"+str(count['two']), (10, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"3 : \"+str(count['three']), (10, 85), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"4 : \"+str(count['four']), (10, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"5 : \"+str(count['five']), (10, 115), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"6 : \"+str(count['six']), (10, 130), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"7 : \"+str(count['seven']), (10, 145), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"8 : \"+str(count['eight']), (10, 160), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "#     cv2.putText(frame, \"9 : \"+str(count['nine']), (10, 175), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    \n",
    "    letters=[]\n",
    "    for i in string.ascii_lowercase:\n",
    "        letters.append(i)\n",
    "    nums=[]\n",
    "    for i in range (190,190+15*21,15):\n",
    "        nums.append(i)\n",
    "    \n",
    "    for l,n in zip(letters,nums):\n",
    "        cv2.putText(frame, l+\" : \"+str(count[l]), (10, n), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "\n",
    "\n",
    "    cv2.putText(frame, \"u : \"+str(count['u']), (75, 40), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"v : \"+str(count['v']), (75, 55), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"w : \"+str(count['w']), (75, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"x : \"+str(count['x']), (75, 85), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"y : \"+str(count['y']), (75, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"z : \"+str(count['z']), (75, 115), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    \n",
    "      # Drawing the ROI\n",
    "    # The increment/decrement by 1 is to compensate for the bounding box\n",
    "    cv2.rectangle(frame, (180-1, 9), (520+1, 411), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[10:410, 180:520]\n",
    "    roi = cv2.resize(roi, (300, 300))\n",
    "  \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(gray,(5,5),2)\n",
    "    # #blur = cv2.bilateralFilter(roi,9,75,75)\n",
    "   \n",
    "\n",
    "    th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "    ret, test_image = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    " \n",
    "    test_image = cv2.resize(test_image, (300,300))\n",
    "    cv2.imshow(\"test\", test_image)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "            break\n",
    "    if interrupt & 0xFF == ord('0'):\n",
    "            cv2.imwrite(directory1+'0/'+str(count['zero'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('1'):\n",
    "#         cv2.imwrite(directory+'1/'+str(count['one'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('2'):\n",
    "#         cv2.imwrite(directory+'2/'+str(count['two'])+'.jpg', roi)       \n",
    "#     if interrupt & 0xFF == ord('3'):\n",
    "#         cv2.imwrite(directory+'3/'+str(count['three'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('4'):\n",
    "#         cv2.imwrite(directory+'4/'+str(count['four'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('5'):\n",
    "#         cv2.imwrite(directory+'5/'+str(count['five'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('6'):\n",
    "#         cv2.imwrite(directory+'6/'+str(count['six'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('7'):\n",
    "#         cv2.imwrite(directory+'7/'+str(count['seven'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('8'):\n",
    "#         cv2.imwrite(directory+'8/'+str(count['eight'])+'.jpg', roi)\n",
    "#     if interrupt & 0xFF == ord('9'):\n",
    "#         cv2.imwrite(directory+'9/'+str(count['nine'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('a'):\n",
    "        cv2.imwrite(directory1+'A/'+str(count['a'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('b'):\n",
    "        cv2.imwrite(directory1+'B/'+str(count['b'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('c'):\n",
    "        cv2.imwrite(directory1+'C/'+str(count['c'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('d'):\n",
    "        cv2.imwrite(directory1+'D/'+str(count['d'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('e'):\n",
    "        cv2.imwrite(directory1+'E/'+str(count['e'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('f'):\n",
    "        cv2.imwrite(directory1+'F/'+str(count['f'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('g'):\n",
    "        cv2.imwrite(directory1+'G/'+str(count['g'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('h'):\n",
    "        cv2.imwrite(directory1+'H/'+str(count['h'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('i'):\n",
    "        cv2.imwrite(directory1+'I/'+str(count['i'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('j'):\n",
    "        cv2.imwrite(directory1+'J/'+str(count['j'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('k'):\n",
    "        cv2.imwrite(directory1+'K/'+str(count['k'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('l'):\n",
    "        cv2.imwrite(directory1+'L/'+str(count['l'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('m'):\n",
    "        cv2.imwrite(directory1+'M/'+str(count['m'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('n'):\n",
    "        cv2.imwrite(directory1+'N/'+str(count['n'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('o'):\n",
    "        cv2.imwrite(directory1+'O/'+str(count['o'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('p'):\n",
    "        cv2.imwrite(directory1+'P/'+str(count['p'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('q'):\n",
    "        cv2.imwrite(directory1+'Q/'+str(count['q'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('r'):\n",
    "        cv2.imwrite(directory1+'R/'+str(count['r'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('s'):\n",
    "        cv2.imwrite(directory1+'S/'+str(count['s'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('t'):\n",
    "        cv2.imwrite(directory1+'T/'+str(count['t'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('u'):\n",
    "        cv2.imwrite(directory1+'U/'+str(count['u'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('v'):\n",
    "        cv2.imwrite(directory1+'V/'+str(count['v'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('w'):\n",
    "        cv2.imwrite(directory1+'W/'+str(count['w'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('x'):\n",
    "        cv2.imwrite(directory1+'X/'+str(count['x'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('y'):\n",
    "        cv2.imwrite(directory1+'Y/'+str(count['y'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('z'):\n",
    "        cv2.imwrite(directory1+'Z/'+str(count['z'])+'.jpg', roi)        \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e78962",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f948cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\"):\n",
    "    os.makedirs(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Train\"):\n",
    "    os.makedirs(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\train\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Valid\"):\n",
    "    os.makedirs(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\valid\")\n",
    "if not os.path.exists(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Test\"):\n",
    "    os.makedirs(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c578cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data\"\n",
    "path1 = \"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\"\n",
    "\n",
    "for i in os.listdir(path+\"\\\\Train\"):\n",
    "    if not os.path.exists(path1+\"\\\\Train\\\\\"+i):\n",
    "        os.makedirs(path1+\"\\\\Train\\\\\"+i)\n",
    "        os.makedirs(path1+\"\\\\Valid\\\\\"+i)\n",
    "        #os.makedirs(path1+\"\\\\Test\\\\\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minValue = 70\n",
    "def func(path):    \n",
    "    frame = cv2.imread(path)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),2)\n",
    "\n",
    "    th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "    ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sets in os.listdir(path):\n",
    "    for dire in os.listdir(path+f'\\\\{sets}'):\n",
    "        for file in os.listdir(path+f'\\\\{sets}\\\\'+f'{dire}'):\n",
    "            orignalpath=path+f'\\\\{sets}\\\\{dire}\\\\{file}'\n",
    "            newpath=path1+f'\\\\{sets}\\\\{dire}\\\\{file}'\n",
    "            img = cv2.imread(orignalpath, 0)\n",
    "            bw_image = func(orignalpath)\n",
    "            cv2.imwrite(newpath, bw_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084abea",
   "metadata": {},
   "source": [
    "# Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c889554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 416,410\n",
      "Trainable params: 416,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "sz=64\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(sz, sz, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "classifier.add(Convolution2D(128, (3, 3), activation='relu', padding = 'valid'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "#classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "#classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=26, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n",
    "\n",
    "\n",
    "# Step 2 - Preparing the train/test data and training the model\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc57a159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13000 images belonging to 26 classes.\n",
      "Found 3900 images belonging to 26 classes.\n",
      "Found 3900 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Train\",target_size=(sz, sz),batch_size=10,class_mode='categorical')\n",
    "valid_set= train_datagen.flow_from_directory(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Valid\", target_size=(sz, sz),batch_size=10,class_mode='categorical')\n",
    "                                                 \n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\"D:\\\\College\\\\Sem 4\\\\Mini Project\\\\Live Data Processed\\\\Valid\",target_size=(sz, sz),batch_size=10,class_mode='categorical')\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe9c55c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(training_set)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b4c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1300/1300 [==============================] - 83s 64ms/step - loss: 0.7344 - accuracy: 0.7992 - val_loss: 1.8530 - val_accuracy: 0.7174\n",
      "Epoch 2/10\n",
      "1300/1300 [==============================] - 90s 69ms/step - loss: 0.1241 - accuracy: 0.9642 - val_loss: 2.1690 - val_accuracy: 0.6608\n",
      "Epoch 3/10\n",
      "1300/1300 [==============================] - 92s 71ms/step - loss: 0.1030 - accuracy: 0.9729 - val_loss: 2.8241 - val_accuracy: 0.6418\n",
      "Epoch 4/10\n",
      "1300/1300 [==============================] - 93s 71ms/step - loss: 0.0841 - accuracy: 0.9798 - val_loss: 2.4566 - val_accuracy: 0.7105\n",
      "Epoch 5/10\n",
      "1300/1300 [==============================] - 94s 72ms/step - loss: 0.0867 - accuracy: 0.9787 - val_loss: 2.3855 - val_accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "1300/1300 [==============================] - 99s 76ms/step - loss: 0.0624 - accuracy: 0.9850 - val_loss: 2.3090 - val_accuracy: 0.7495\n",
      "Epoch 7/10\n",
      "1300/1300 [==============================] - 95s 73ms/step - loss: 0.0962 - accuracy: 0.9818 - val_loss: 2.8385 - val_accuracy: 0.6872\n",
      "Epoch 8/10\n",
      "1300/1300 [==============================] - 95s 73ms/step - loss: 0.0657 - accuracy: 0.9883 - val_loss: 2.7580 - val_accuracy: 0.7156\n",
      "Epoch 9/10\n",
      "1300/1300 [==============================] - 95s 73ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.6364 - val_accuracy: 0.7438\n",
      "Epoch 10/10\n",
      "1300/1300 [==============================] - 96s 74ms/step - loss: 0.0477 - accuracy: 0.9910 - val_loss: 3.6474 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fcbef94bb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code copied from - https://keras.io/preprocessing/image/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "classifier.fit(\n",
    "        training_set,\n",
    "        epochs=10,\n",
    "        validation_data=valid_set,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(x=test_set,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_true=test_labels,y_pred=predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083aae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix',cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize = (15,10))\n",
    "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks=np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print(\"Confusion Matrix without normalization\")\n",
    "    print(cm)\n",
    "    \n",
    "    thresh=cm.max()/2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
    "        plt.text(j,i,cm[i,j],horizontalalignment=\"center\",color=\"white\" if cm[i,j]>thresh else \"black\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c298e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels,title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1eea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
